{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Shot Learning with Siamese Networks\n",
    "\n",
    "This is the jupyter notebook that accompanies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "All the imports are defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Set of helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Class\n",
    "A simple class to manage configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    training_dir = \"./data/faces/training/\"\n",
    "    testing_dir = \"./data/faces/testing/\"\n",
    "    train_batch_size = 64\n",
    "    train_number_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset Class\n",
    "This dataset generates a pair of images. 0 for geniune pair and 1 for imposter pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "        #we need to make sure approx 50% of images are in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                #keep looping till the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1]==img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                #keep looping till a different class image is found\n",
    "                \n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] !=img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "        \n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Image Folder Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset = dset.ImageFolder(root=Config.training_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       ,should_invert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising some of the data\n",
    "The top row and the bottom row of any column is one pair. The 0s and 1s correspond to the column of the image.\n",
    "1 indiciates dissimilar, and 0 indicates similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mBrokenPipeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-fd6fffe6a662>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m                         \u001B[0mnum_workers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                         batch_size=8)\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mdataiter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvis_dataloader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    350\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    351\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 352\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    353\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    292\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0m_SingleProcessDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0m_MultiProcessingDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m    799\u001B[0m             \u001B[1;31m#     before it starts, and __del__ tries to join but will get:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    800\u001B[0m             \u001B[1;31m#     AssertionError: can only join a started process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 801\u001B[1;33m             \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    802\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_index_queues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_queue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    803\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_workers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    110\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    111\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 112\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    113\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    114\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    221\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    320\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 322\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     87\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mBrokenPipeError\u001B[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "vis_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=8)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neural Net Definition\n",
    "We will use a standard convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8*100*100, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 5))\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=Config.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork().cuda()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.0005 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(0,Config.train_number_epochs):\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "        img0, img1 , label = data\n",
    "        img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = net(img0,img1)\n",
    "        loss_contrastive = criterion(output1,output2,label)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i %10 == 0 :\n",
    "            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "show_plot(counter,loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some simple testing\n",
    "The last 3 subjects were held out from the training, and will be used to test. The Distance between each image pair denotes the degree of similarity the model found between the two images. Less means it found more similar, while higher values indicate it found them to be dissimilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       ,should_invert=False)\n",
    "\n",
    "test_dataloader = DataLoader(siamese_dataset,num_workers=6,batch_size=1,shuffle=True)\n",
    "dataiter = iter(test_dataloader)\n",
    "x0,_,_ = next(dataiter)\n",
    "\n",
    "for i in range(10):\n",
    "    _,x1,label2 = next(dataiter)\n",
    "    concatenated = torch.cat((x0,x1),0)\n",
    "    \n",
    "    output1,output2 = net(Variable(x0).cuda(),Variable(x1).cuda())\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f}'.format(euclidean_distance.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}